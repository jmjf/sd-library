# Prepare data

## XML to JSON

Based on what I'm seeing, xml2js is the package to use. I'll also use glob to get all the xml files.

-  `npm install --save-dev xml2js glob`
-  copy xml data to project db directory
-  create `prepare-data.ts`
   -  start by processing a single file and writing raw to JSON file
   -  build a function to convert data into a usable object
      -  lots of finding parts, figuring out how to get what I want, deal with sometimes missing values
   -  Some work around getting the promises working
      -  promisify glob so I can await a list of files
      -  xml2js generates promises, so result of `files.map()` is an array of promises parsing XML
      -  `await Promise.all()` the array of promises to get all the data

Change to process all files and merge into a single JSON array (can probably do something like `files.map(data.map(parseEntry)).flat()`).

Result is `db/harvard.json`, an array of objects containing book data.

**COMMIT: CHORE: convert Harvard library XML into JSON I can use** Reference: prepare data

## Parsing Dublin Core JSON

Sample query 1: https://api.lib.harvard.edu/v2/items.dc.json?subject.topic=translations%20and%20japanese%20literature&languageCode=eng

To parse the result:

-  data array is in `.items.dc`
-  title -> `.title`
-  authors -> `.creator`, `.contributor`, `.editor` -- each may be single or an array
-  lc -> sometimes in the `.subject` array, but no specific field
-  dd -> sometimes in the `.subject` array, but no specific field
-  isbn -> usually in `.identifier` array, may or may not be tagged as an ISBN
-  abstract -> not available
-  genres -> `.subject` array, except see call numbers above
-  language -> `.language`
-  publisher -> `.publisher`
-  publishedDate-> not available

Based on that preliminary analysis, while DC is easier to read, it's missing data or configured so data is impossible to reliable extract.

## Parsing Mods JSON

Sample query 1: https://api.lib.harvard.edu/v2/items.json?subject.topic=translations%20and%20japanese%20literature&languageCode=eng

To parse the result:

-  data array is in `.items.mods`
-  title -> `.titleInfo` plus `.nonSort`, `.title`, `.subtitle` in that order
-  authors -> `.name.namePart` plus `.name.role.roleTerm.#text`
-  lc -> `.classification[x].#text` where `.classification[x].@authority` is `lcc`
-  dd -> `.classification[x].#text` where `.classification[x].@authority` is `ddc`
-  isbn -> `.identifier[x].#text` where `.identifier[x].@type` is `isbn`
-  abstract -> `.abstract.#text`
-  genres -> replace with subject
   -  subject ->
      -  if `.subject[x].@authority` is `rvm`, exclude (non-English)
      -  if `.subject[x].topic` is an array, `.subject[x].topic`
      -  if `.subject[x].topic` is not an array, add to array `.subject[x].topic`
      -  if `.subject[x].genre` add to array
      -  if `.subject[x].geographic` add to array
      -  if `.subject[x].temporal` add to array
      -  alternatively, consider selecting only when `@authority` is `lcsh` or `fast` (in that order of priority) and note different styles for the two
-  language -> `.language[x].languageTerm[y].#text` where `...@type` is `text`
   -  alternatively, get codes and translate against ISO list
-  publisher -> `originInfo.publisher`
-  publishedDate-> `originInfo.dateIssued` -- may be an array (pick [0]); clean it

So, it might be worthwhile to rebuild this using Harvard JSON format data.
Could replace `@authority`, `#text`, `@type` in JSON string with same names minus special characters and make references easier.
Format has some other `@` tags, but they aren't useful for what I'm doing.

I decided to use the JSON mods output. It was, in some ways, harder to parse, but I think that's because it forced me to find most of the issues in the data. For example, most attributes may be a single value or an array. Some of the array entries may be arrays. Object structures vary. I do a lot of "if it's an array, find the entry with X, if it isn't an array, use it; then if it's defined, pick the value else return an empty value." I'm more confident I have reasonable data now.

-  Rewrote `db/prepare-data.js`
-  Lots of tracking down twists and turns in the data
-  Removed `xml2js` because I don't need it with the JSON formatted inputs
-  Extracted new starting files (~1600 resources)

### Queries I used to get data

-  https://api.lib.harvard.edu/v2/items.json?name=murakami%20OR%20akutagawa%20OR%20kawabata%20OR%20dazai%20OR%20kawakami%20OR%20mishima%20OR%20miyazawa%20OR%20natsume%20OR%20tanizaki&languageCode=eng&limit=250
   -  paginate start=250, 500, 750
   -  `authors*.mods.json`
-  https://api.lib.harvard.edu/v2/items.json?subject.topic=japan%20AND%20history&languageCode=eng&limit=250
   -  paginate start=250
   -  `history*.mods.json`
-  https://api.lib.harvard.edu/v2/items.json?subject.topic=translations%20and%20japanese%20literature&languageCode=eng&limit=100
   -  `lit.mods.json`

**COMMIT: CHORE: extract data from Harvard JSON format data** Reference: use JSON source

Adding a link to the Harvard API docs
https://wiki.harvard.edu/confluence/display/LibraryStaffDoc/LibraryCloud+APIs

Will let it fall into a later commit.
